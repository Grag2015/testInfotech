## Анализ связи между количеством покупок на уровне, сложностью и оттоком.

выполнил: *Григорий Михолап*  
дата: *18/01/2016*

```{r setoptions, echo=FALSE, warning=FALSE, message=FALSE}
# глобальные настройки для chunks
library(knitr)
opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
```

```{r echo=FALSE, results='hide'}
# пользовательская ф-я для вывода параметров регрессионной модели
printlm <- function(model){
  tempsum <- summary(model)
  cat("Residual standard error:", format(signif(tempsum$sigma, 
                                                4)), "on", tempsum$df[2L], "degrees of freedom")
  cat("\n")
  cat("Multiple R-squared:  ", round(tempsum$r.squared, digits=4),	"Adjusted R-squared:  ",
      round(tempsum$adj.r.squared, digits=4))
  cat("\n")
  cat("F-statistic: ", round(tempsum$fstatistic[1],2), "on", round(tempsum$fstatistic[2],0), 
      "and", round(tempsum$fstatistic[3],0), "DF,  p-value:",
      format.pval(pf(tempsum$fstatistic[1L],tempsum$fstatistic[2L], 
                     tempsum$fstatistic[3L], lower.tail = FALSE)))
}

# пользовательские функции для график попарных корреляций
    panel.density <- function(x, ...) {
        n.groups <-  1
        adjust <-  1
        groups = NULL
        if (n.groups > 1) {
            levs <- levels(groups)
            for (i in 1:n.groups) {
                xx <- x[levs[i] == groups]
                dens.x <- try(density(xx, adjust = adjust, na.rm = TRUE), 
                  silent = TRUE)
                if (!inherits(dens.x, "try-error")) {
                  lines(dens.x$x, min(x, na.rm = TRUE) + dens.x$y * 
                    diff(range(x, na.rm = TRUE))/diff(range(dens.x$y, 
                    na.rm = TRUE)), col = col[i])
                }
                else warning("cannot estimate density for group ", 
                  levs[i], "\n", dens.x, "\n")
                rug(xx, col = col[i])
            }
        }
        else {
            dens.x <- density(x, adjust = adjust, na.rm = TRUE)
            lines(dens.x$x, min(x, na.rm = TRUE) + dens.x$y * 
                diff(range(x, na.rm = TRUE))/diff(range(dens.x$y, 
                na.rm = TRUE)))
            rug(x)
        }
#         if (do.legend) 
#             legendPlot(position = if (is.null(legend.pos)) 
#                 "topright"
#             else legend.pos)
#         do.legend <<- FALSE
    }

# функция для расчет коэффициентов детерминации
panel.cor <- function(x, y, digits=2, prefix="", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- cor(x[!is.na(x*y)], y[!is.na(x*y)])
    txt <- format(c(r^2, 0.123456789), digits=digits)[1]
    txt <- paste(prefix, txt, sep="")
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * max(abs(r), 0.25))
}

```

**Задание:**

Есть данные по уровням match-3 игры: сложность, отток пользователь, количество покупок. Проанализировать, как связаны между собой сложность уровней и отток на этих уровнях.
Сложность определяется как количество попыток до победы на уровне, отток – процент людей, которые не перешли на следующий уровень относительно всех тех, кто начал первый уровень. Проверить, есть ли связь между количеством покупок на уровнях и этими показателями. Данные представлены в файле “Data.xls” на вкладке «Сложность уровней».


**Выводы кратко:** 


**Замечание** по поводу программного кода:
Программный код, который используется в отчете, в т.ч. и некоторые операции (такие как загрузка и подготовка данных для анализа) не были включены в отчет, при необходимости все эти данные вы можете найти [по ссылке](https://github.com/Grag2015/testInfotech/blob/master/Task%201%20match-3.Rmd) 
```{r echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# **Замечание** для воспроизводимости работы:
# перед загрузкой вкладка "Сложность уровней" была сохранена в формате csv
# в файле с именем "task1.csv"
# (Выполнено в MS Excel 2010: Файл -> Сохранить как -> CSV (разделители - запятые))
# и далее в текстовом редакторе разделители разрядов "," были заменены на "."
```


```{r  echo=FALSE, results='hide', warning=FALSE, message=FALSE}

# ЗАГРУЗКА И ПРЕДОБРАБОТКА

#  setwd("d:/Grag/R/R-studio/testInfotech/")
# читаем данные
df <-  read.csv("task1.csv", sep = ";")

# просмотр загруженного файла показал, что загрузились 2 пустых столбца №5 и 6, удалим их
df <- df[,-c(5:6)]

# переименуем столбцы
names(df) <- c("level","slozn","ottok", "pokupki")

# Отток пользователя при загрузке был преобразован в факторную переменную
# удалим знак "%" и преобразуем столбец в числовой формат
df$ottok <- as.numeric(gsub("%","",df$ottok))

```

```{r  echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# Подключаем нужные библиотеки
library("dplyr")
library("ggplot2")
library("lattice") 
library("xtable")
library("car")
library(lubridate)
library(reshape2)
```

## 1. Предварительный анализ данных
При загрузке данных я переименовал столбцы и наша таблица теперь выглядит так
```{r}
head(df)
```

При анализе нам понадобится факторная версия переменной `level`, мы разобъем переменную `level` на 3 уровня [ 1, 35) [35, 68) [68,100] и сохраним в новой переменной `level3`
```{r}
library(Hmisc)
df$level3 <- cut2(df$level, g=3)
head(df)
```

Посмотрим есть ли в нашей таблице пропущенные значения
```{r}
sapply(df, function(e) sum(is.na(e)))
```
Пропущенных значений нет


посмотрим на квантили значений наших переменных
```{r}
summary(df[,-1])
```
Параметр `level3` факторный, остальные параметры - числовые, распределения несимметричные, но явных выбросов нет. 

## 2. Разведочный анализ
Вспоминая, что наша задача найти зависимости между переменными Отток, Покупки и Сложность
для начала посмотрим на попарные корреляции между нашими переменными.
```{r  fig.width=8,  fig.height=6}
    pairs(df[-c(5)], diag.panel=panel.density, upper.panel=panel.cor, lower.panel=panel.smooth)
```

Анализ данного графика показывает, что между покупками и сложностью существует достаточно сильная линейная связь (коэффициент корреляции `0.58`). Есть слабая корреляция в парах Уровень-сложность и Уровень-Отток, оставшиеся пары значений практически не коррелируют. Например, увеличение сложности практически не влияет на отток (!) и количество покупок тоже не связано с оттоком - это выглядит несколько неожиданно.

## 3. Анализ зависимости между переменными
### 3.1. Анализ связи между покупками и сложностью

Рассмотрим более детально связь между количеством покупок и сложностью уровня. Выше мы видели, что Отток не коррелирует с этими переменными, и поэтому его не стоит добавлять в модель. Но можно попробовать добавить в модель в качестве предиктора уровень игры, который показывает небольшую корреляцию со сложностью.
```{r}
ggplot(data=df, aes(x=slozn, y=pokupki,col=cut2(df$level,g=3)))+geom_point(size=3)+xlab("Сложность уровня")+ylab("Количество покупок")+scale_color_discrete(name="Уровни игры")
```

мы видим что зависимость между покупками и сложностью похожа на линейную, также расскраска графика по группам переменной `level3` подсказывает, что в модель можно попробовать включить и взаимодействие переменных `slozn:level3`.  

Построим 3 модели: 1. со всеми переменными, 2. с переменными `level3` и `slozn`, 3. только с переменной `slozn`. И сравним эти модели с помощью информационного критерия Акаике (который реализован в `R` с помощью функции `AIC`)

```{r echo=T}
fit1 <- lm(pokupki~., data = df[,-c(1)]) #1. со всеми переменными
fit2 <- lm(pokupki~slozn, data = df) # 2. только с переменной `slozn`
fit3 <- lm(pokupki~level3:slozn, data = df) # 3. с переменной `level3` и `slozn`
AIC(fit1,fit2,fit3)
```
Предпочтение нужно отдавать моделям с меньшими значениями AIC, в нашем случае наилучшей будет модель `fit3` с переменными `level3` и `slozn`. Поэтому остановимся на данной модели, т.к. она к тому же достаточно простая и легко интерпретируется.  
Замечание: также модель `fit3` имеет минимальную сумму квадратов ошибок и максимальный показатель Adjusted R-squared среди рассмотренных моделей, что также свидетельстует в ее пользу.

**Диагностика модели**  
проверим нашу линейную модель на соответствие основным требованиям

**1.1** нормальность остатков (тест Шапиро-Вилка)
```{r}
test1 <- shapiro.test(fit3$residuals)
test1
#summary(powerTransform(df$pokupki))
```
Требование НЕ выполнено! Тест показал, что остатки не распределены нормально

**1.2** визуальная оценка нормальности остатков (QQ-plot) 
```{r}
#hist(fit3$residuals, breaks = 30)
qqPlot(fit3, labels=row.names(df), id.method="identify",
       simulate=TRUE, main="Q-Q Plot")
```

визуальная оценка подсказывает, что такое отклонение от нормального распределения можно исправить степенным преобразованием зависимой переменной (об этом ниже)

**2.** независимость остатков (тест Дарбина-Уотсона)
```{r}
test2 <- durbinWatsonTest(fit3)
test2
```
Требование выполнено! Т.к. p.value>0.05, то остатки независимы 

**3.** тест на гомоскедастичность остатков
```{r}
test3 <- ncvTest(fit3)
test3
```
Требование выполнено! Т.к. p.value>=0.05, то дисперсия остатков равномерна (т.е. гомоскедастичность выполняется)

**Подгонка модели**
Для того, чтобы привести остатки к нормальному распределению, можно воспользоваться степенным преобразованием зависимой переменной. Функция `powerTransform` рекомендует нужную степень. 
```{r}
summary(powerTransform(df$pokupki))
```
Как видим, рекомендуется извлечь кубический корень из зависимой переменной. Попробуем перестроить нашу модель

```{r echo=T}
fit3up <- lm(I(pokupki^(1/3))~level3:slozn, data = df)
```
и проверить заново все тесты
```{r echo=FALSE, results='hide'}
# 1.1 нормальность остатков (тест Шапиро-Вилка)
test12 <- shapiro.test(fit3up$residuals)
# независимость остатков (тест Дарбина-Уотсона)
test22 <- durbinWatsonTest(fit3up)
# 3.1 гомоскедастичность остатков
test32 <- ncvTest(fit3up) 
```

Тест  | Результат исходный | Результат после преобразования
------------- | ------------- | -------------
Нормальность остатков  | `r round(test1$p.value,4)` `(NO)` |  `r round(test12$p.value,4)` `(YES)`
Независимость остатков  | `r round(test2$p,4)` `(YES)` | `r round(test22$p,4)` `(YES)`
Гомоскедастичность остатков | `r round(test3$p,4)`  `(YES)` | `r round(test32$p,4)` `(YES)`

Т.о. мы видим, что наша модель удовлетворяет всем необходимы требованиям. 

Посмотрим на основные параметры построенной модели
```{r results='hold'}
printlm(fit3up)
```
```{r results='asis',  echo=FALSE}
xt <- xtable(summary(fit3up))
print(xt, type="html")
```

Коэффициент `Adjusted R-squared = 0.56` говорит о том, что наша модель объясняет 56% вариативности зависимой переменной `pokupki` что достаточно хороший показатель.  
Все коэффициенты статистически значимы. Аналитически данную зависимость можно записать формулой `pokupki^(1/3) = 1.93 + F(level)*slozn + Err` , 
где `F` - функция от уровня, заданная таблицей:

Level  | [ 1, 35)  |  [35, 68)  |  [68,100]
------------- | ------------- | ------------- | -------------
F(level)  | 0.44  | 0.25  | 0.22

а `Err` - нормально распределенная по закону N(`r round(mean(fit3up$residuals))`,`r round(sd(fit3up$residuals),2)`) случайная величина. `Err` - ошибка модели, которая неизбежно возникает, т.к. не все факторы влияющие на зависимую переменную учтены в модели. По сути в нашей модели мы учли только сложность и уровень. Другие факторы из имеющихся у нас, модель улучшить не смогли.

Визуализация результатов
```{r}
ggplot(data=df, aes(x=slozn, y=(pokupki)^(1/3), col=level3)) + geom_point() + facet_grid(level3~.) + geom_smooth(method = "lm")+xlab("Сложность уровня")+ylab("Количество покупок (в степени 1/3)")+scale_color_discrete(name="Уровни игры")
```

т.е. мы видим, что наша линейная модель для каждого из 3-х уровней содержит отдельную аппроксимирующую прямую. И на начальных уровнях (красный цвет) это прямая растет более резко, чем на последующих уровнях, это значит, что увеличение сложности на 1 дает больший прирост покупок на начальных уровнях.

**Замечание**: при построении модели в зависимости целей построения модели, можно пренебречь некоторыми требованиями диагностики модели. В нашем случаем мы могли бы остановиться на модели без степенного преобразования, это бы дало нам более простую и интерпретируемую модель. 

### 3.2. Анализ связи оттока с другими показателями
Предварительный анализ показал, что отток не коррелирует ни со сложностью, ни с покупками, посмотрим как отток зависит от уровня игры
```{r}
ggplot(data=df, aes(x=level, y=ottok))+geom_point()+geom_smooth()
```

Мы видим, что отток после 25-го уровня очень близок к нулю. Среднее значение оттока на уровнях 25-100 равно `r mean(df[25:100,"ottok"])`%. Такие низкие значения оттока с увеличеним уровня игры мы имеем из-за методики расчета оттока - "отток – процент людей, которые не перешли на следующий уровень *относительно всех тех, кто начал первый уровень*".  
Давайте посмотрим на *локальный* отток на каждом уровне, т.е. процент людей, которые не перешли на следующий уровень *относительно всех тех, кто начал данный уровень*". Возможно данная переменная будет коррелировать с другими переменным.

Локальный отток `ottok2` рассчитывается следующим образом
```{r echo=T}
df$ottok2 <- df$ottok
s <- df$ottok[1]
df$ottok2[1] <- df$ottok[1]
for (i in 2:100) {
    df$ottok2[i] <- df$ottok[i]/(100-s)
    s <- s + df$ottok[i]
}
```

Проверим коррелирует ли локальный отток с нашими переменными Сложность, Покупки и Уровень соответственно
```{r}
cor(df$slozn,df$ottok2)
cor(df$pokupki,df$ottok2)
cor(df$level,df$ottok2)
```
как видим, связи не наблюдается, мое предположение о новой переменной не оправдалось.  

Но все-таки польза от введения новой переменной есть - обнаружились уровни, на которых локальный отток выше 30%, т.е. с данных уровней ушли треть дошедших до него игроков. Это следующию уровни:
```{r}
df$level[df$ottok2>0.3]
```
При этом сложность заданий на этих уровнях не выше средней, что же явилось причиной столь высокого оттока? Стоит внимательней проанализировать поведение пользователей на этих уровнях, возможно в интерфейсе игры на этих уровнях есть проблемы с юзабилити или вовсе какие-то баги.

## 3.3. Анализ среднего числа покупок на уровне
Среднее число покупок на уровне рассчитывается следующим фрагментом кода и сохраняется в новый столбец `pokupkiAver`. Данный показатель характеризует средние объемы покупок одного пользователя.  
```{r}
s <- 0
for (i in 1:100) {
    df$pokupkiAver[i] <- df$pokupki[i]/(100-s)
    s <- s + df$ottok[i]
}
```

Предварительный анализ (не включенный в отчет) распределения и коррелиции для переменной `pokupkiAver` показал, что среднее число покупок на уровне достаточно сильно коррелирует с уровнем - это можно проанализировать подробнее

```{r}
ggplot(data = df, aes(x=level, y = pokupkiAver))+geom_point()
```

построим линейную модель, описывающую данную зависимость
учитывая ступенчатый характер зависимости в качестве предикторов возьмем `level` и `level3`. Также на диаграмме выше видны в правом верхнем углу подозрительно большие значения, с помощью теста Бонферони найдем выбросы и удалим их при построении модели (я выбросил четыре значения - строки 97,98,87,92)


```{r}
fit <- lm(pokupkiAver~level*level3, data = df)
tt <- outlierTest(fit) # ищем выбросы - 97,98,87
fit <- lm(pokupkiAver~level*level3, data = df[-c(97,98,87),])
```
```{r echo=TRUE}
tt <- outlierTest(fit) # ищем выбросы - 92
fit <- lm(pokupkiAver~level*level3, data = df[-c(97,98,87,92),])
```
```{r results='hold'}
printlm(fit)
```
```{r results='asis',  echo=FALSE}
xt <- xtable(summary(fit))
print(xt, type="html")
```
Мы получили достаточно точную модель `Adjusted R-squared = 0,79` связывающую уровни `level` и среднее количество покупок на уровне `pokupkiAver`. Аналитически эту зависимость можно записать формулой `pokupkiAver = -280 + 4.3*level` где `level>=68`.
Т.о. начиная примерно с 68-го уровня, каждый игрок переходя на следующий уровень делает на 4 покупки больше, чем сделал на предыдущем уровне. Вообще данная зависимость интересна таким резким ростом покупок в конце игры, возможно это объясняется тем, что в конце игры остаются только самые вовлеченные игроки, которые твердо решили дойти до конца невзирая на затраты.

```{r}
ggplot(data=df, aes(x=slozn, y=ottok, col=level3)) + geom_point() 

ggplot(data=df, aes(x=slozn, y=ottok2, col=level3)) + geom_point(size=2) 
ggplot(data=df[df$level3=="[68,100]",], aes(x=slozn, y=ottok2, col=level3)) + geom_point(size=2) +geom_smooth(method = "lm")
```


**Результат:** 
   **1**. Сложность связана с количеством покупок следующей формулой   
   `pokupki^(1/3) = 1.93 + F(level)*slozn + Err` , где `F` - функция от уровня, заданная таблицей:

Level  | [ 1, 35)  |  [35, 68)  |  [68,100]
------------- | ------------- | ------------- | -------------
F(level)  | 0.44  | 0.25  | 0.22

а `Err` - нормально распределенная по закону N(`r round(mean(fit3up$residuals))`,`r round(sd(fit3up$residuals),2)`) случайная величина.  
    **2**. Также обнаружена интересная зависимость связывающая уровни `level` и среднее количество покупок на уровне `pokupkiAver`.   
    `pokupkiAver = -280 + 4.3*level` где `level>=68`
    **3**. Для оттока обнаружена только связь с уровнями, 
 ___________   

```{r echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# knit2html('Task 3 Advert channels.Rmd', encoding="UTF-8")
# browseURL('Task 3 Advert channels.Rmd')

```
```{r}
fit <- lm(slozn~ottok*pokupki*level3, data=df)
fit <- lm(ottok~slozn*pokupki, data=df)
fit <- lm(pokupki~slozn*ottok, data=df)
fit <- lm(slozn~pokupki*ottok, data=df)
fit <- lm(slozn~ottok2*pokupki, data=df)
fit <- lm(slozn~pokupki + ottok:pokupki, data=df)
fit <- lm(slozn~ottok*pokupki*level3, data=df[df$level3!="[ 1, 35)",])
fit <- lm(slozn~ottok:pokupki + pokupki, data=df[df$level3!="[ 1, 35)",])
summary(fit)
```

```{r}
ggplot(data=df, aes(x=slozn, y=pokupki, col=cut2(df$ottok, g=3))) + geom_point() 
```

